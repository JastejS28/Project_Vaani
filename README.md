:

ğŸ—£ï¸ Project Vaani â€“ AI-Powered Digital Companion
Project Vaani is a voice-first AI digital companion built to help digitally inexperienced and multilingual Indian citizens access government welfare schemes with ease. It simplifies complex bureaucratic processes into natural, spoken conversations.

ğŸ“Œ Table of Contents
ğŸ¯ Project Aim & Vision

ğŸ” Complete Technical Workflow

ğŸ§° Tech Stack

âš™ï¸ Getting Started

ğŸ“¦ Prerequisites

ğŸ“¥ Installation

ğŸ” Environment Variables

ğŸš€ Running the Application

ğŸ“ Project Structure

ğŸ¯ Project Aim & Vision
Aim: Build Project Vaani â€“ a voice-first AI companion enabling easy access to government schemes for all citizens, especially those with limited digital skills.

Vision: Ensure inclusive access where anyoneâ€”regardless of language or tech literacyâ€”can understand, apply for, and benefit from government support simply through voice.

ğŸ” Complete Technical Workflow
This outlines the complete process from user speech to audio reply:

User Interface (React + Vite)
Mobile-responsive web app launches and prompts user to choose a language (e.g., English or Hindi).

Voice Input (Frontend)
User speaks. Browser uses MediaRecorder API to capture audio.

Speech-to-English Translation (Groq Whisper)
Backend sends audio to Groqâ€™s Whisper /translations API â†’ gets English text.

Core Logic Processing (External API)
English text sent to:
https://adityachanna04-project.onrender.com/chat â†’ gets English response.

Translation to Native Language (Groq LLM)
If original input was Hindi â†’ Groq LLaMA3 model translates response back to Hindi.

Text-to-Speech (ElevenLabs API)
Final response is converted to audio using language-specific voices.

Frontend Delivery
JSON with response text, audio URL, and transcription is sent to frontend â†’ user hears response.

ğŸ§° Tech Stack
ğŸ–¥ï¸ Frontend
React (with Vite)

JavaScript

ğŸ› ï¸ Backend
Node.js

Express.js

ğŸ™ï¸ AI & Audio Services
Speech-to-Text: Groq Whisper (whisper-large-v3)

Logic + Translation: Groq LLaMA3

Text-to-Speech: ElevenLabs API

âš™ï¸ Getting Started
ğŸ“¦ Prerequisites
Node.js v18+

npm (or Yarn)

ğŸ“¥ Installation
bash
Copy
Edit
# Clone the repository
git clone https://github.com/JastejS28/Project_Vaani.git
cd Project_Vaani
Backend Setup
bash
Copy
Edit
cd backend
npm install
Frontend Setup
bash
Copy
Edit
cd ../frontend
npm install
ğŸ” Environment Variables
In the backend/ directory, create a .env file with:

env
Copy
Edit
PORT=5000

# API Keys
GROQ_API_KEY="your_groq_key"
ELEVENLABS_API_KEY="your_elevenlabs_key"

# Logic API
EXTERNAL_API_URL="https://adityachanna04-project.onrender.com/chat"
Also, create an empty folder for audio uploads:

bash
Copy
Edit
cd backend
mkdir uploads
ğŸš€ Running the Application
Run backend and frontend in separate terminals:

Backend
bash
Copy
Edit
cd backend
npm start
# Runs at http://localhost:5000
Frontend
bash
Copy
Edit
cd frontend
npm run dev
# Opens at http://localhost:5173
You're ready to talk to Project Vaani in your browser! ğŸ§ ğŸ¤

ğŸ“ Project Structure
bash
Copy
Edit
project-vaani/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ outputs/           # AI-generated audio responses
â”‚   â”œâ”€â”€ uploads/           # Temp user audio
â”‚   â”œâ”€â”€ .env               # API keys & config
â”‚   â”œâ”€â”€ index.js           # Main Express server
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioRecorder.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessage.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FormModal.jsx / .css
â”‚   â”‚   â”‚   â””â”€â”€ Icons.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ ...
ğŸ’¡ Built with care to empower every voice.

